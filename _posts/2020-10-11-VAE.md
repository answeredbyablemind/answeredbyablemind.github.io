---
title: Variational AutoEncoder
sidebar:
  nav: docs-ko
aside:
  toc: true
key: 20201011
tags: 기계학습
---

※ 이 포스팅은 미술관에 GAN 딥러닝 실전 프로젝트의 결과와 소스 코드를 이용해 작성한 것임을 밝힙니다.

※ 이 포스팅의 소스 코드는 박해선 님의 깃허브 레포에서 확인하실 수 있습니다.

# Prerequisites

해당 포스팅을 이해하기 위해선 다음의 내용에 대해 알고 오시는 것을 추천드립니다.

* [AutoEncoder](https://angeloyeo.github.io/2020/10/10/autoencoder.html)
* [정보 엔트로피](https://angeloyeo.github.io/2020/10/26/information_entropy.html)
* [KL divergence](https://angeloyeo.github.io/2020/10/27/KL_divergence.html)

# 오토 인코더 짧게 복습

Variational AutoEncoder(VAE)는 기본적으로 AutoEncoder(AE)의 형태를 그대로 유지하고 있다.

따라서, VAE를 잘 이해하기 위해선 AE의 특성을 잘 파악하고, 어떤 부분에서 AE의 한계점이 있으며, 그 한계점들을 극복하기 위해 VAE는 어떤 보완책들을 내놓았는지 알아볼 필요가 있다.

[AutoEncoder](https://angeloyeo.github.io/2020/10/10/autoencoder.html)편의 내용을 짧게 복습해보자.

기본적으로 AE는 데이터를 압축하고 압축 해제하는 과정을 거치게 만든 뉴럴네트워크이다.

<p align ="center">
  <img width = "400" src = "https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2020-10-10-autoencoder/pic1.png">
  <br>
  그림 1. 오토인코더의 구조와 역할
</p>

이런 일을 수행할 수 있도록 오토인코더를 학습할 때는 인코더 부(部)의 입력과 디코더 부(部)의 출력은 모두 동일한 입력데이터가 될 수 있도록 한다.

굳이 왜 입력데이터를 넣고 똑같은 출력데이터를 얻는가 하면, 입력 데이터를 표방할 수 있는 조금 더 낮은 차원의 데이터(표현 벡터)를 비선형적으로 얻을 수 있기 때문이다.

이 때, 데이터를 압축해 얻어낸 새로운 종류의 벡터를 '표현 벡터(representation vector)' 혹은 latent factor라고 부른다.

가령, 28*28 = 784 차원인 MNIST 데이터셋을 이용해 2차원 표현 벡터를 얻게 된다고 하면 다음과 같이 2차원 평면 상에 label을 붙여 표현해 볼 수 있다.

<p align ="center">
  <img width = "400" src = "https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2020-10-10-autoencoder/pic3.png">
  <br>
  그림 2. MNIST 데이터의 representation vector의 시각화
</p>

여기까지의 "압축" 과정을 통해 고차원 데이터를 저차원으로 변환시켜주는 과정을 "인코딩"이라고 하고, 이러한 일을 수행하는 뉴럴네트워크 부(部)를 "인코더"라고 부른다.

뿐만 아니라 AE는 "압축해제"를 수행할 수도 있는데, 그림 2에 있는 표현 벡터 공간(혹은 latent space)에서 임의로 좌표를 선정해 해당 좌표의 데이터를 디코딩함으로써 전혀 보지 못했던 새로운 샘플을 생성할 수도 있다.

<p align = "center">
  <img src ="https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2020-10-11-VAE/pic0.png">
  <br>
  그림 3. 표현 벡터 공간(혹은 latent space) 상에서 랜덤 샘플링을 통해 얻은 표현 벡터를 디코딩한 결과
</p>

# 오토인코더의 한계점과 보완 방법

그렇다면, "압축"과 "압축 해제"의 기능이 의도한 것 처럼 구현되어 보이는 오토인코더(AutoEncoder, AE)는 어떤 부분에서 성능을 개선시킬 수 있을까?

첫 번째로는 오토인코더는 지금껏 보지 못했던 데이터들을 생성할 때의 퀄리티가 떨어진다. 즉, AE의 latent space에서 빈 공간에서부터 생성된 데이터들은 품질이 떨어진다. 어떻게 생각하면 AE의 디코더의 디코딩 기능이 인코더가 특정 데이터를 인코딩 해 놓은 좌표에만 잘 작동하게끔 오버피팅(overfitting)되어 있는 상태라고도 말할 수 있을 것이다.

두 번째 한계점은 표현 벡터의 벡터 공간 상의 벡터들이 (0, 0)에 대칭이거나 값이 제한되어 있지 않다. 예를 들어 그림 2의 표현 벡터들의 분포를 보면 y축 상에서 양수 영역보다 음수 영역에 더 많은 포인트들이 분포하고 있다. 다시 말해 인코딩 시 표현 벡터들의 위치를 선택하는 특정한 규칙이 없다보니, 디코딩 시에는 항상 인코더가 표현 벡터 벡터 공간의 어떤 좌표에 해당 데이터를 옮겨 담았는지 매번 확인해서 sampling을 해야하는 번거로움이 있는 것이다.

또, 세 번째 한계점은 어떤 숫자들은 매우 작은 영역에 밀집되어 있는데, 또 어떤 숫자들은 넓은 지역에 퍼져 있다는 점이다. 가령, 그림 2를 보면 숫자 0은 좌측 상단에 넓게 퍼져있는 것에 반해 숫자 9는 중앙에 빨간색으로 아주 작게 밀집되어 있는 것을 알 수 있다.

그렇다면, 이러한 한계점 세 가지를 어떻게 해결하는 것이 좋을까?


## 첫 번째 한계점에 대한 보완책

첫 번째 한계점에 대해서는 인코더가 데이터를 "압축"할 때 원래 인코더가 위치시키려고 했던 표현 벡터 벡터 공간 상의 정확한 그 위치가 아닌 그 위치에서 살짝 벗어난 곳에 점을 찍어줄 수 있도록 인코더를 수정해야 한다. randomness를 주는 방법은 여러가지가 있을 수 있지만 일반적으로 많이 사용되는 방법 중 하나는 Gaussian 분포를 이용하는 것이다.

<p align = "center">
  <img width = "500" src ="https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2020-10-11-VAE/pic1.png">
  <br>
  그림 4. 인코더가 표현 벡터 공간에 데이터를 인코딩 할 때 randomness를 추가해주면 디코더의 overfitting 현상을 막을 수 있다.
</p>

[//]:# (그런데, 왜 각각의 label들이 꼭 하나의 cluster를 normal 분포처럼 이루도록 결과가 얻어지는 걸까?)

여기서 하나 궁금한 점이 생길 수 있다. 가령, 그림 4에서와 같이 '8'이라는 형태의 입력 데이터가 들어왔다고 했을 때 VAE에서 찍어줄 인코딩 좌표(즉, sampling 할 Gaussian 분포의 평균값)와 해당 Gaussian 분포의 분산 값은 어떻게 계산할 것인가라는 문제이다.

VAE에서는 방금 언급한 평균과 분산 값을 모두 각각의 Fully Connected 뉴럴넷에서 계산하여 출력한 값으로 계산하여 사용한다. 물론 여기서 평균값과 분산값의 계산을 맡게 될 Fully Connected 뉴럴넷은 본인이 계산하고 있는 값이 평균과 분산이라는 사실은 모른채 VAE의 학습 과정에 들어가게 될 것이다. 

여기서 randomness를 추가해주기 위해 

<center>
  <b>
  "계산된 평균값" + 평균이 0이고 "계산된 표준편차" 만큼의 표준편차를 갖는 정규분포로부터 샘플링된 값
  </b>
</center>

이라는 좌표에 표현 벡터가 찍히게 된다.

(여기서 "계산된 평균값" 혹은 "계산된 표준편차"는 꼭 스칼라 값일 필요는 없다. 만약 표현 벡터의 벡터공간을 2차원 벡터공간으로 생각한다면 "계산된" 평균값/표준편차는 2차원 벡터로 생각하면 된다.)

학습 과정에서 비슷한 데이터들(즉, 결론적으로는 label이 같은)은 "계산된 평균값"이 유사해 질 것이고, 이 과정에서 "계산된 표준편차" 역시도 모든 데이터에 대해서 작아질 것이므로 (뉴럴넷도 게속 학습시켜주면 점점 지금 보고 있는 데이터들이 지금껏 봤던 데이터들 중 어떤 것과 닮았는지 확신을 더 갖게 된다.) 결국 각 label들의 분포는 정규분포의 형태로 클러스터링 되게 된다.




